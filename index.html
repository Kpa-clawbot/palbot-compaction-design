<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Palbot Context Compaction â€” Design Doc</title>
<style>
  :root { --bg: #0d1117; --surface: #161b22; --border: #30363d; --text: #e6edf3; --muted: #8b949e; --accent: #58a6ff; --green: #3fb950; --orange: #d29922; --red: #f85149; }
  * { box-sizing: border-box; margin: 0; padding: 0; }
  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; background: var(--bg); color: var(--text); line-height: 1.6; padding: 2rem; max-width: 900px; margin: 0 auto; }
  h1 { font-size: 2rem; margin-bottom: 0.25rem; }
  h2 { font-size: 1.4rem; margin-top: 2.5rem; margin-bottom: 1rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border); color: var(--accent); }
  h3 { font-size: 1.1rem; margin-top: 1.5rem; margin-bottom: 0.75rem; color: var(--text); }
  p { margin-bottom: 1rem; }
  .subtitle { color: var(--muted); margin-bottom: 2rem; font-size: 0.95rem; }
  .subtitle a { color: var(--accent); text-decoration: none; }
  .subtitle a:hover { text-decoration: underline; }
  ul, ol { margin-bottom: 1rem; padding-left: 1.5rem; }
  li { margin-bottom: 0.4rem; }
  code { font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace; background: var(--surface); padding: 0.2em 0.4em; border-radius: 4px; font-size: 0.9em; border: 1px solid var(--border); }
  pre { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 1rem; overflow-x: auto; margin-bottom: 1rem; }
  pre code { background: none; border: none; padding: 0; font-size: 0.85em; }
  table { width: 100%; border-collapse: collapse; margin-bottom: 1rem; }
  th, td { text-align: left; padding: 0.6rem 1rem; border: 1px solid var(--border); }
  th { background: var(--surface); color: var(--accent); font-weight: 600; }
  td { background: var(--bg); }
  strong { color: #f0f6fc; }
  .callout { background: var(--surface); border-left: 4px solid var(--accent); padding: 1rem 1.25rem; border-radius: 0 8px 8px 0; margin-bottom: 1.5rem; }
  .callout.warn { border-left-color: var(--orange); }
  .callout.good { border-left-color: var(--green); }
  .diagram { background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 1.25rem; margin-bottom: 1.5rem; font-family: 'SFMono-Regular', Consolas, monospace; font-size: 0.85em; white-space: pre; overflow-x: auto; line-height: 1.5; }
  .tag { display: inline-block; padding: 0.15em 0.5em; border-radius: 12px; font-size: 0.8em; font-weight: 600; }
  .tag-new { background: rgba(63,185,80,0.15); color: var(--green); border: 1px solid rgba(63,185,80,0.3); }
  .tag-mod { background: rgba(210,153,34,0.15); color: var(--orange); border: 1px solid rgba(210,153,34,0.3); }
  .tag-unchanged { background: rgba(139,148,158,0.15); color: var(--muted); border: 1px solid rgba(139,148,158,0.3); }
  .tag-resolved { background: rgba(63,185,80,0.15); color: var(--green); border: 1px solid rgba(63,185,80,0.3); }
  footer { margin-top: 3rem; padding-top: 1.5rem; border-top: 1px solid var(--border); color: var(--muted); font-size: 0.85rem; }
  footer a { color: var(--accent); text-decoration: none; }
</style>
</head>
<body>

<h1>Palbot Context Compaction</h1>
<p class="subtitle">
  Design doc for <a href="https://github.com/iamsix/palbot">iamsix/palbot</a> &middot; <code>modules/gemini.py</code><br>
  Authors: Iavor + Stinkmeaner &middot; February 2026
</p>

<h2>Problem</h2>
<p><code>!clai</code> and <code>!sclai</code> are stateless â€” every call dumps up to 24 hours of raw channel history from SQLite into a single Claude API call. This works but:</p>
<ul>
  <li><strong>Wasteful:</strong> Re-sends entire 24h log every time</li>
  <li><strong>No long-term memory:</strong> Anything older than 24h is gone</li>
  <li><strong>Scales poorly:</strong> Busy channels = massive context = expensive calls</li>
  <li><strong>No tuning:</strong> Hardcoded 24h window, no way to adjust at runtime</li>
</ul>

<h2>Solution</h2>
<p>Add a compaction layer between SQLite log retrieval and the Claude API call. Recent messages stay raw; older messages get summarized by a cheaper model and cached.</p>

<div class="callout good">
  <strong>Key insight:</strong> The raw window <em>stretches</em> back to meet the compaction boundary â€” there are never gaps between compacted and raw context.
</div>

<h2>Architecture</h2>
<p>The context sent to Claude will look like:</p>
<pre><code>[System prompt]
[Compacted summary: last N days, excluding recent window]
[Raw messages: from compaction boundary through now â€” minimum X hours]
[User's question + any web search results (sclai only)]</code></pre>

<h3>Context Window Diagram</h3>
<div class="diagram">Day -7          Compaction boundary          Now
|--- compacted summary ---|--- raw (stretches) ---|

Compacted = summarized by Sonnet, cached in SQLite
Raw = verbatim messages from Logger DB</div>

<h3>Re-compaction Strategy: Full Re-summarization <span class="tag tag-resolved">decided</span></h3>

<p>When re-compaction fires, it's a <strong>full re-summarization</strong> â€” not cumulative. The old summary is thrown away entirely, and Sonnet re-summarizes the full <code>compact_days</code> window from raw logs.</p>

<div class="callout">
  <strong>Why not cumulative?</strong> Cumulative summaries (feeding the old summary + new messages to produce an updated summary) drift over time. Each pass loses nuance, amplifies biases, and the summary gradually becomes a game of telephone. After a few cycles it'd be unrecognizable. Full re-summarization is more expensive per-compaction but keeps the summary grounded in actual messages.
</div>

<p><strong>Cost is manageable:</strong> Re-compaction only fires when the raw window exceeds <code>recompact_raw_hours</code> (default 12h) or <code>recompact_raw_tokens</code> (default 15K) â€” whichever hits first. In a moderately active channel, that's maybe once or twice a day. One Sonnet call per re-compaction is cheap.</p>

<h3>Re-compaction Triggers</h3>
<p>Re-compaction fires when <strong>either</strong> threshold is exceeded:</p>
<ol>
  <li><strong>Time-based:</strong> Raw window exceeds <code>recompact_raw_hours</code> (default 12h)</li>
  <li><strong>Size-based:</strong> Raw window exceeds <code>recompact_raw_tokens</code> (default 15000 tokens)</li>
</ol>

<p>Whichever hits first wins. This prevents the case where a busy channel racks up 50K tokens of raw messages in 4 hours â€” time-based wouldn't catch it, but size-based does.</p>

<div class="callout">
  <strong>Skip compaction entirely</strong> if the raw window has fewer messages than would fit in <code>compact_max_tokens</code> â€” there's no point summarizing 800 tokens of chat into a 2000-token summary.
</div>

<p>When re-compaction fires:</p>
<ol>
  <li>Pull the full <code>compact_days</code> window from Logger SQLite</li>
  <li>Split at <code>raw_hours</code> boundary</li>
  <li>Send the older portion to <code>compact_model</code> for <strong>fresh</strong> summarization (old summary discarded)</li>
  <li>New summary replaces the old one in cache</li>
  <li>Raw window shrinks back to <code>raw_hours</code></li>
</ol>

<h3>Error Handling</h3>
<p>If the compaction API call fails (Sonnet timeout, rate limit, network error):</p>
<ul>
  <li><strong>During <code>!claireset</code>:</strong> Reply with the error. Cache stays deleted. Admin can retry.</li>
  <li><strong>During auto re-compaction:</strong> Log the error, keep the old cache, skip compaction this round. Next <code>!clai</code> call will try again. The raw window keeps growing until compaction succeeds.</li>
  <li><strong>During cold start:</strong> Reply with just the raw messages (no summary). Log the error. Next call retries.</li>
</ul>

<div class="callout warn">
  Errors should be visible â€” don't silently swallow compaction failures. If an admin can see it broke, they can <code>!claireset</code> to retry.
</div>

<h2>Storage</h2>
<p>New SQLite database created on first run at <code>logfiles/ai_cache.db</code>. Separate from the Logger DB (which has years of data and shouldn't be touched).</p>

<h3>Tables</h3>
<pre><code>CREATE TABLE compaction_cache (
    channel_id INTEGER PRIMARY KEY,
    guild_id INTEGER NOT NULL,
    oldest_snowflake INTEGER NOT NULL,   -- start of compacted range
    newest_snowflake INTEGER NOT NULL,   -- end of compacted range
    summary_text TEXT NOT NULL,
    model_used TEXT NOT NULL,
    token_count INTEGER,
    created_at REAL NOT NULL,
    updated_at REAL NOT NULL
);

CREATE TABLE settings (
    guild_id INTEGER,
    channel_id INTEGER,                  -- NULL = guild-wide default
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    updated_at REAL NOT NULL,
    PRIMARY KEY (guild_id, channel_id, key)
);</code></pre>

<h2>Configurable Settings</h2>

<h3>Context Settings</h3>
<table>
  <tr><th>Key</th><th>Default</th><th>Description</th></tr>
  <tr><td><code>compact_days</code></td><td>7</td><td>How many days back to pull for compaction</td></tr>
  <tr><td><code>raw_hours</code></td><td>6</td><td>Minimum hours of uncompacted recent messages</td></tr>
  <tr><td><code>compact_max_tokens</code></td><td>2000</td><td>Target max size for compacted summary</td></tr>
  <tr><td><code>recompact_raw_hours</code></td><td>12</td><td>Time-based re-compaction trigger</td></tr>
  <tr><td><code>recompact_raw_tokens</code></td><td>15000</td><td>Size-based re-compaction trigger (whichever hits first)</td></tr>
  <tr><td><code>search_max_tokens</code></td><td>8000</td><td>Max tokens for web search results (<code>!sclai</code> only)</td></tr>
</table>

<h3>Model Settings</h3>
<table>
  <tr><th>Key</th><th>Default</th><th>Description</th></tr>
  <tr><td><code>answer_model</code></td><td><code>claude-opus-4.6</code></td><td>Model for <code>!clai</code>/<code>!sclai</code> responses</td></tr>
  <tr><td><code>compact_model</code></td><td><code>claude-sonnet-4.5</code></td><td>Model for summarization</td></tr>
</table>

<p>Settings are per-channel (with guild-wide fallback). Stored in <code>ai_cache.db</code>.</p>

<h2>Web Search Token Budget (<code>!sclai</code>) <span class="tag tag-resolved">decided</span></h2>

<p>Search results are appended after the raw messages but <strong>count toward the total context budget</strong>. Without a cap, a broad search query could dump 20k+ tokens of web content, dwarfing the conversation context.</p>

<p><strong>How it works:</strong></p>
<ol>
  <li>Web search runs and collects results as before</li>
  <li>Results are truncated to <code>search_max_tokens</code> (default 8000, ~2-3 full page extracts)</li>
  <li>If results exceed the cap, they're trimmed from the bottom (least relevant results dropped first)</li>
  <li>The truncated results are appended to the context as <code>[Web Search Results]</code> block</li>
</ol>

<p><strong>Tuning:</strong> <code>!claiconfig search_max_tokens 5000</code> to tighten, or <code>12000</code> if you want more web context. The default of 8000 tokens (~6k words) is enough for most queries without blowing up costs.</p>

<div class="callout">
  <strong>Note:</strong> Search results are ephemeral â€” they're NOT included in compaction. Only the bot's answer (which synthesizes the search) gets logged and eventually compacted.
</div>

<h2>Commands</h2>

<h3>Existing <span class="tag tag-mod">modified</span></h3>
<ul>
  <li><code>!clai &lt;question&gt;</code> â€” Now uses compacted context + raw window instead of flat 24h dump</li>
  <li><code>!sclai &lt;question&gt;</code> â€” Same, plus web search results appended (capped at <code>search_max_tokens</code>)</li>
</ul>

<h3>New <span class="tag tag-new">new</span></h3>
<ul>
  <li><code>!claiconfig</code> â€” Show all current settings for this channel</li>
  <li><code>!claiconfig &lt;key&gt; &lt;value&gt;</code> â€” Change a setting</li>
  <li><code>!claireset</code> â€” Nuke cache and immediately rebuild (see below)</li>
  <li><code>!claireset all</code> â€” Nuke and rebuild all channels immediately</li>
  <li><code>!claistatus</code> â€” Server-wide usage stats + per-channel cache summary</li>
  <li><code>!claistatus #channel</code> â€” Detailed view for a specific channel</li>
</ul>

<div class="callout warn">
  All config/admin commands are <code>@commands.is_owner()</code> only.
</div>

<h3><code>!claireset</code> â€” Nuke &amp; Rebuild</h3>

<p>Blows away the existing compaction cache for this channel and immediately rebuilds it. Not a lazy invalidation â€” it does the Sonnet call right now so the next <code>!clai</code> hits a warm cache.</p>

<p><strong>Flow:</strong></p>
<ol>
  <li>Delete existing cache entry for this channel</li>
  <li>Pull full <code>compact_days</code> window from Logger SQLite</li>
  <li>Summarize everything except the last <code>raw_hours</code> via <code>compact_model</code></li>
  <li>Store fresh summary, set boundary at <code>now - raw_hours</code></li>
  <li>Reply with confirmation: summary token count, messages covered, time range</li>
</ol>

<p><strong>When to use:</strong></p>
<ul>
  <li>After a big topic shift â€” stale summary is confusing Claude</li>
  <li>After changing <code>compact_days</code> or <code>compact_max_tokens</code> â€” apply immediately</li>
  <li>Debugging â€” "the bot is acting weird"</li>
</ul>

<h3><code>!claistatus</code> â€” Usage Stats</h3>

<p>Every <code>!clai</code>, <code>!sclai</code>, and compaction call is logged to a <code>usage_log</code> table. <code>!claistatus</code> aggregates across all channels.</p>

<p><strong>Server-wide view (<code>!claistatus</code>):</strong></p>
<pre><code>ðŸ“Š Claude AI Stats

Cache: 3 channels active
  #general: warm (2h ago) | #shitpost: warm (5h ago) | #dev: cold

Usage (last 7d / all time):
  !clai:   23 / 156 calls  |  142K / 891K tokens  |  $4.07 / $28.41
  !sclai:   8 /  42 calls  |   89K / 470K tokens  |  $2.73 / $15.20
  Compactions: 4 / 31       |   31K / 198K tokens  |  $0.19 / $1.22
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total:   35 / 229 calls  |  262K / 1.56M tokens  |  $6.99 / $44.83</code></pre>

<p><strong>Per-channel view (<code>!claistatus #general</code>):</strong></p>
<pre><code>ðŸ“Š Claude AI Stats â€” #general

Cache: warm (built 2h ago)
  Summary: 1,847 tokens covering 6.2 days
  Raw window: 8.1 hours (297 messages)
  Next re-compaction: ~3.9h

Usage (last 7d / all time):
  !clai:  14 / 89 calls  |  98K / 612K tokens  |  $2.81 / $19.53
  !sclai:  5 / 28 calls  |  61K / 340K tokens  |  $1.87 / $11.02
  Compactions: 2 / 18     |  19K / 122K tokens  |  $0.12 / $0.75
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total:  21 / 135 calls  | 178K / 1.07M tokens  |  $4.80 / $31.30</code></pre>

<p><strong>Storage:</strong></p>
<pre><code>CREATE TABLE usage_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    channel_id INTEGER NOT NULL,
    guild_id INTEGER NOT NULL,
    command TEXT NOT NULL,          -- 'clai', 'sclai', 'compaction'
    input_tokens INTEGER NOT NULL,
    output_tokens INTEGER NOT NULL,
    cost_usd REAL,
    model TEXT NOT NULL,
    timestamp REAL NOT NULL
);</code></pre>

<p>Every API call logs a row. Cost is calculated from hardcoded model pricing (Opus for answers, Sonnet for compaction). Token counts come from the API response <code>usage</code> field.</p>

<h2>Flow</h2>

<h3>First Call (Cold Cache)</h3>
<ol>
  <li>Check <code>ai_cache.db</code> for this channel â€” nothing there</li>
  <li>Pull last <code>compact_days</code> of messages from Logger SQLite</li>
  <li>Split at <code>raw_hours</code> boundary</li>
  <li>Send older portion to <code>compact_model</code> with summarization prompt</li>
  <li>Store summary in <code>compaction_cache</code> table</li>
  <li>Send to <code>answer_model</code>: system prompt + summary + raw messages + question</li>
</ol>

<h3>Subsequent Calls (Warm Cache)</h3>
<ol>
  <li>Load cached summary from <code>ai_cache.db</code></li>
  <li>Pull raw messages from cached <code>newest_snowflake</code> through now</li>
  <li>Check if raw portion exceeds either <code>recompact_raw_hours</code> or <code>recompact_raw_tokens</code>
    <ul>
      <li><strong>If no:</strong> Send to <code>answer_model</code>: system prompt + cached summary + raw messages + question</li>
      <li><strong>If yes:</strong> Re-compact first (full re-summarization), then answer</li>
    </ul>
  </li>
  <li>Skip compaction entirely if raw tokens &lt; <code>compact_max_tokens</code> â€” no point summarizing into something bigger</li>
</ol>

<h3>Cache Invalidation</h3>
<ul>
  <li><code>!claireset</code> â€” nuke and immediate rebuild</li>
  <li>Re-compaction â€” automatic when raw window exceeds time or token threshold</li>
  <li>Cache is keyed by <code>channel_id</code> â€” each channel is independent</li>
</ul>

<h2>Compaction Prompt</h2>
<pre><code>Summarize the following Discord conversation concisely. Preserve:
- Key facts, decisions, and conclusions
- Important context about users and their preferences
- Any ongoing topics or threads of discussion
- Your own previous responses and positions (marked with [BOT])

Omit:
- Casual greetings, reactions, and small talk
- Redundant back-and-forth
- Messages with no informational value

Keep the summary under {compact_max_tokens} tokens.</code></pre>

<h2>Token Counting</h2>
<p>Use a simple heuristic: <code>len(text) / 4</code> for approximate token count. No need for a tokenizer dependency â€” we're setting thresholds, not doing exact math.</p>

<h2>What Doesn't Change <span class="tag tag-unchanged">unchanged</span></h2>
<ul>
  <li><code>!ai</code> and <code>!sai</code> (Gemini commands)</li>
  <li><code>!chat</code> / <code>!newchat</code> (Gemini multi-turn)</li>
  <li>Logger cog â€” read-only access, no modifications</li>
  <li><code>config/config.py</code> â€” no new config entries needed</li>
  <li>Safety settings, mention resolution, web search (<code>!sclai</code>)</li>
</ul>

<h2>Implementation Plan</h2>
<ol>
  <li>Add <code>ai_cache.py</code> helper module (DB init, cache CRUD, settings CRUD, usage logging)</li>
  <li>Modify <code>!clai</code> in <code>gemini.py</code> to use compacted context</li>
  <li>Modify <code>!sclai</code> similarly (with <code>search_max_tokens</code> cap)</li>
  <li>Add <code>!claiconfig</code>, <code>!claireset</code>, <code>!claistatus</code> commands</li>
  <li>Add usage logging to all API call paths (answer, compaction)</li>
  <li>Test on a quiet channel first, then busy ones</li>
</ol>

<h2>Resolved Decisions <span class="tag tag-resolved">resolved</span></h2>
<table>
  <tr><th>Question</th><th>Decision</th><th>Rationale</th></tr>
  <tr>
    <td>Cumulative vs full re-summarization?</td>
    <td><strong>Full re-summarization</strong></td>
    <td>Cumulative drifts over time â€” game of telephone. Full is grounded in actual messages. Cost is minimal (one Sonnet call per re-compaction).</td>
  </tr>
  <tr>
    <td>Search results count toward thresholds?</td>
    <td><strong>Capped separately</strong></td>
    <td>New <code>search_max_tokens</code> setting (default 8000). Results truncated before appending. Not included in compaction â€” only the bot's synthesized answer persists.</td>
  </tr>
  <tr>
    <td>Separate <code>!claicompact</code> command?</td>
    <td><strong>Merged into <code>!claireset</code></strong></td>
    <td>Originally separate, but it was just <code>!claireset</code> + immediate rebuild. Simpler to have one command that always nukes and rebuilds. No reason to leave a cold cache.</td>
  </tr>
</table>

<footer>
  Generated from <a href="https://github.com/iamsix/palbot">iamsix/palbot</a> design notes &middot; Updated Feb 8, 2026
</footer>

</body>
</html>
